{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed09552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 00:55:09.671897: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-16 00:55:10.152471: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744736110.417540  532609 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744736110.487795  532609 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744736110.995896  532609 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744736110.995931  532609 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744736110.995934  532609 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744736110.995935  532609 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-16 00:55:11.041005: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, losses, metrics, regularizers, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a5f1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constant for the character set\n",
    "CHARSET = \"0123456789abcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dd86de3-a26a-4cbf-9c2f-b0d15f4d43f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_pad_image(img, target_size):\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "\n",
    "    # Calculate scale to fit the longer side into target_size\n",
    "    scale = target_size / max(height, width)\n",
    "    new_height = int(height * scale)\n",
    "    new_width = int(width * scale)\n",
    "\n",
    "    # Resize with aspect ratio\n",
    "    resized = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Pad the image to target_size\n",
    "    pad_height = target_size - new_height\n",
    "    pad_width = target_size - new_width\n",
    "    top = pad_height // 2\n",
    "    bottom = pad_height - top\n",
    "    left = pad_width // 2\n",
    "    right = pad_width - left\n",
    "\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3005c21d-6e87-4b68-9cd3-1a82d1a9e287",
   "metadata": {},
   "source": [
    "## Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d3bf7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 1) Load Segmented Images\n",
    "# -----------------------------------------------------------------------------\n",
    "def load_segmented_images(folder_path, test_size=0.1):\n",
    "    X_list, Y_list = [], []\n",
    "    test_dict = dict()\n",
    "    captcha_names = os.listdir(folder_path)\n",
    "    train_names, test_names = train_test_split(captcha_names, test_size=test_size, random_state=42)\n",
    "    for captcha_name in captcha_names:\n",
    "        captcha_dir = os.path.join(folder_path, captcha_name)\n",
    "        if not os.path.isdir(captcha_dir) or len(captcha_name) == 0:\n",
    "            continue\n",
    "        image_files = [fname for fname in os.listdir(captcha_dir)\n",
    "                if fname.lower().endswith(\".png\") and fname.startswith(\"char_\")]\n",
    "        for filename in image_files:\n",
    "            try:\n",
    "                char_index = int(filename.split(\"_\")[1].split(\".\")[0])\n",
    "            except Exception:\n",
    "                continue\n",
    "            if char_index >= len(captcha_name):\n",
    "                continue\n",
    "            label_char = captcha_name[char_index]\n",
    "            if label_char not in CHARSET:\n",
    "                continue\n",
    "            label_idx = CHARSET.index(label_char)\n",
    "            img_path = os.path.join(captcha_dir, filename)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = resize_and_pad_image(img, 32)\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            label = np.zeros(len(CHARSET), dtype=np.float32)\n",
    "            label[label_idx] = 1.0\n",
    "\n",
    "            if captcha_name in train_names:\n",
    "                X_list.append(img)\n",
    "                Y_list.append(label)\n",
    "\n",
    "            else:\n",
    "                test_dict.setdefault(captcha_name, ([], []))\n",
    "                test_dict[captcha_name][0].append(img)\n",
    "                test_dict[captcha_name][1].append(label)\n",
    "    return X_list, Y_list, test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3019f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load and split segmented data\n",
    "segment_folder = \"segmented_new\"\n",
    "X_list, Y_list, test_dict = load_segmented_images(segment_folder)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_list, Y_list, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_val = np.array(X_val)\n",
    "Y_val = np.array(Y_val)\n",
    "\n",
    "print(f\"Loaded {len(X_train)} training characters, {len(X_val)} validation characters and {len(test_dict)} test strings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image.fromarray(X_val[1000].reshape(32, 32) * 255).convert(\"L\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08154991-6df1-44fa-bc82-3526bd1b5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 2) Enhanced Model Architecture (without TensorFlow Addons)\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_model(num_classes=36):\n",
    "    inputs = layers.Input(shape=(32, 32, 1))\n",
    "    \n",
    "    # Augmentation layers\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        layers.RandomRotation(0.1),         \n",
    "        layers.RandomZoom(0.1),           \n",
    "        layers.RandomTranslation(0.1, 0.1),   \n",
    "        layers.RandomContrast(0.2),        \n",
    "        layers.GaussianNoise(0.1)          \n",
    "    ])\n",
    "\n",
    "    x = data_augmentation(inputs)\n",
    "    \n",
    "    # Stem block  \n",
    "    x = layers.Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(256, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv2D(256, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(1024, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv2D(1024, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # Head\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Custom learning rate schedule\n",
    "    # lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "    #     initial_learning_rate=0.001,\n",
    "    #     decay_steps=10000,\n",
    "    #     decay_rate=0.9)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, weight_decay=1e-6)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "        metrics=[metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9aff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = build_model(num_classes=len(CHARSET))\n",
    "model.summary()\n",
    "\n",
    "# Enhanced callbacks\n",
    "callbacks = [\n",
    "tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_model.h5', save_best_only=True, monitor='val_categorical_accuracy'),\n",
    "tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6),\n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_categorical_accuracy', patience=10, \n",
    "    restore_best_weights=True, mode='max', baseline=0.4),\n",
    "tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "\n",
    "# Train with class weights\n",
    "class_counts = np.sum(Y_train, axis=0)\n",
    "class_weights = {i: 1.0 / (count + 1e-5) for i, count in enumerate(class_counts)}\n",
    "class_weights = {k: v / sum(class_weights.values()) * len(CHARSET) for k, v in class_weights.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5240dd2-c4b6-4c2f-a3fa-eb733e664f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "X_train, Y_train,\n",
    "epochs=100,\n",
    "batch_size=128,\n",
    "validation_data=(X_val, Y_val),\n",
    "callbacks=callbacks,\n",
    "class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "468f62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 3) Evaluation Function\n",
    "# -----------------------------------------------------------------------------\n",
    "def evaluate_captcha(model, test_dict):\n",
    "    total_chars = 0\n",
    "    correct_chars = 0\n",
    "    total_strings = len(test_dict)\n",
    "    correct_strings = 0\n",
    "    tqdm_bar = tqdm(total=total_strings, desc=\"Evaluating CAPTCHA strings\")\n",
    "\n",
    "    for captcha_name, (X_data, Y_data) in test_dict.items():\n",
    "        total_chars += len(X_data)\n",
    "        \n",
    "        pred = model.predict(np.array(X_data), verbose=0)\n",
    "        pred_labels = np.argmax(pred, axis=1)\n",
    "        true_labels = np.argmax(np.array(Y_data), axis=1)\n",
    "        \n",
    "        is_string_correct = True\n",
    "        for i in range(len(pred_labels)):\n",
    "            if pred_labels[i] == true_labels[i]:\n",
    "                correct_chars += 1\n",
    "            else:\n",
    "                is_string_correct = False\n",
    "        if is_string_correct:\n",
    "            correct_strings += 1\n",
    "        tqdm_bar.update(1)\n",
    "    \n",
    "    char_accuracy = correct_chars / total_chars * 100\n",
    "    string_accuracy = correct_strings / total_strings * 100\n",
    "    print(f\"\\nCharacter Accuracy: {char_accuracy:.2f}%\")\n",
    "    print(f\"String Accuracy: {string_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc38951-9aa3-48ad-82da-0be833930169",
   "metadata": {},
   "source": [
    "## Results (model trained on original dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cae6f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating CAPTCHA strings: 100%|█████████████| 722/722 [00:35<00:00, 20.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Character Accuracy: 92.43%\n",
      "String Accuracy: 67.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print(\"Final Evaluation:\")\n",
    "evaluate_captcha(model, test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa8c5df3-3ff5-4c54-83a3-81b50bae986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4917 test strings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating CAPTCHA strings: 100%|███████████| 4917/4917 [04:01<00:00, 20.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Character Accuracy: 89.78%\n",
      "String Accuracy: 57.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Evaluate on generated images\n",
    "\n",
    "print(\"Evaluating on GAN images:\")\n",
    "_, _, test_dict_generated = load_segmented_images(\"segmented_generated\", test_size=0.999)\n",
    "evaluate_captcha(model, test_dict_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d5628e-fe32-4df5-a32a-0ac1552d8321",
   "metadata": {},
   "source": [
    "## Training with GAN generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7383e95-93d9-4da4-98d2-4365b2645476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 58499 training characters, 6500 validation characters; 722 test strings from original, 493 test strings from GAN.\n"
     ]
    }
   ],
   "source": [
    "X_list_ori, Y_list_ori, test_dict_ori = load_segmented_images(\"segmented_new\")\n",
    "X_list_gan, Y_list_gan, test_dict_gan = load_segmented_images(\"segmented_generated\")\n",
    "\n",
    "X_list_ori.extend(X_list_gan)\n",
    "Y_list_ori.extend(Y_list_gan)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_list_ori, Y_list_ori, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_val = np.array(X_val)\n",
    "Y_val = np.array(Y_val)\n",
    "\n",
    "print(f\"Loaded {len(X_train)} training characters from original and generated, \\\n",
    "{len(X_val)} validation characters from original and generated; \\\n",
    "{len(test_dict_ori)} test strings from original, \\\n",
    "{len(test_dict_gan)} test strings from generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03da98b1-8c7c-4117-8868-a5e875780f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = build_model(num_classes=len(CHARSET))\n",
    "\n",
    "# Enhanced callbacks\n",
    "callbacks = [\n",
    "tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_model_on_combined_data.h5', save_best_only=True, monitor='val_categorical_accuracy'),\n",
    "tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6),\n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_categorical_accuracy', patience=10, \n",
    "    restore_best_weights=True, mode='max', baseline=0.4),\n",
    "tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "\n",
    "# Train with class weights\n",
    "class_counts = np.sum(Y_train, axis=0)\n",
    "class_weights = {i: 1.0 / (count + 1e-5) for i, count in enumerate(class_counts)}\n",
    "class_weights = {k: v / sum(class_weights.values()) * len(CHARSET) for k, v in class_weights.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e82f936-20bc-4094-a759-700c5f8eff72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.3903 - loss: 2.5682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - categorical_accuracy: 0.3907 - loss: 2.5669 - val_categorical_accuracy: 0.3857 - val_loss: 2.8725 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.6615 - loss: 1.6855"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - categorical_accuracy: 0.6617 - loss: 1.6847 - val_categorical_accuracy: 0.8091 - val_loss: 1.3063 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.7336 - loss: 1.4877"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - categorical_accuracy: 0.7338 - loss: 1.4873 - val_categorical_accuracy: 0.8394 - val_loss: 1.2253 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.7851 - loss: 1.3663"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - categorical_accuracy: 0.7852 - loss: 1.3661 - val_categorical_accuracy: 0.8694 - val_loss: 1.1434 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.8273 - loss: 1.2575"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - categorical_accuracy: 0.8273 - loss: 1.2574 - val_categorical_accuracy: 0.8785 - val_loss: 1.1183 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.8359 - loss: 1.2406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - categorical_accuracy: 0.8359 - loss: 1.2405 - val_categorical_accuracy: 0.8809 - val_loss: 1.1177 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.8512 - loss: 1.1940"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - categorical_accuracy: 0.8513 - loss: 1.1940 - val_categorical_accuracy: 0.8852 - val_loss: 1.1041 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - categorical_accuracy: 0.8542 - loss: 1.1962 - val_categorical_accuracy: 0.8738 - val_loss: 1.1519 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.8609 - loss: 1.1844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - categorical_accuracy: 0.8609 - loss: 1.1844 - val_categorical_accuracy: 0.8923 - val_loss: 1.1030 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - categorical_accuracy: 0.8656 - loss: 1.1855 - val_categorical_accuracy: 0.8834 - val_loss: 1.1430 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - categorical_accuracy: 0.8508 - loss: 1.2382 - val_categorical_accuracy: 0.8842 - val_loss: 1.1605 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.8833 - loss: 1.1587"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - categorical_accuracy: 0.8833 - loss: 1.1587 - val_categorical_accuracy: 0.9132 - val_loss: 1.0713 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - categorical_accuracy: 0.8934 - loss: 1.1228 - val_categorical_accuracy: 0.9125 - val_loss: 1.0676 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - categorical_accuracy: 0.8940 - loss: 1.1216 - val_categorical_accuracy: 0.9129 - val_loss: 1.0696 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - categorical_accuracy: 0.8958 - loss: 1.1168 - val_categorical_accuracy: 0.9117 - val_loss: 1.0755 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9079 - loss: 1.0811"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - categorical_accuracy: 0.9080 - loss: 1.0810 - val_categorical_accuracy: 0.9243 - val_loss: 1.0384 - learning_rate: 2.5000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.9131 - loss: 1.0612"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - categorical_accuracy: 0.9131 - loss: 1.0612 - val_categorical_accuracy: 0.9246 - val_loss: 1.0327 - learning_rate: 2.5000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - categorical_accuracy: 0.9124 - loss: 1.0604 - val_categorical_accuracy: 0.9203 - val_loss: 1.0358 - learning_rate: 2.5000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - categorical_accuracy: 0.9146 - loss: 1.0459 - val_categorical_accuracy: 0.9246 - val_loss: 1.0230 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9196 - loss: 1.0363"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - categorical_accuracy: 0.9196 - loss: 1.0363 - val_categorical_accuracy: 0.9258 - val_loss: 1.0158 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9198 - loss: 1.0286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - categorical_accuracy: 0.9198 - loss: 1.0286 - val_categorical_accuracy: 0.9278 - val_loss: 1.0131 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9241 - loss: 1.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - categorical_accuracy: 0.9241 - loss: 1.0201 - val_categorical_accuracy: 0.9292 - val_loss: 1.0050 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9213 - loss: 1.0235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - categorical_accuracy: 0.9213 - loss: 1.0234 - val_categorical_accuracy: 0.9303 - val_loss: 1.0043 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - categorical_accuracy: 0.9241 - loss: 1.0152 - val_categorical_accuracy: 0.9275 - val_loss: 1.0049 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9274 - loss: 1.0053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - categorical_accuracy: 0.9274 - loss: 1.0052 - val_categorical_accuracy: 0.9306 - val_loss: 1.0048 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.9306 - loss: 0.9942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - categorical_accuracy: 0.9306 - loss: 0.9942 - val_categorical_accuracy: 0.9329 - val_loss: 0.9900 - learning_rate: 1.2500e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - categorical_accuracy: 0.9340 - loss: 0.9871 - val_categorical_accuracy: 0.9322 - val_loss: 0.9877 - learning_rate: 1.2500e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - categorical_accuracy: 0.9391 - loss: 0.9680 - val_categorical_accuracy: 0.9317 - val_loss: 0.9862 - learning_rate: 1.2500e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9407 - loss: 0.9644"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - categorical_accuracy: 0.9407 - loss: 0.9644 - val_categorical_accuracy: 0.9332 - val_loss: 0.9822 - learning_rate: 1.2500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9421 - loss: 0.9583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - categorical_accuracy: 0.9421 - loss: 0.9583 - val_categorical_accuracy: 0.9342 - val_loss: 0.9781 - learning_rate: 1.2500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9431 - loss: 0.9540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - categorical_accuracy: 0.9431 - loss: 0.9540 - val_categorical_accuracy: 0.9360 - val_loss: 0.9775 - learning_rate: 1.2500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.9427 - loss: 0.9511"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - categorical_accuracy: 0.9427 - loss: 0.9511 - val_categorical_accuracy: 0.9372 - val_loss: 0.9735 - learning_rate: 1.2500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - categorical_accuracy: 0.9436 - loss: 0.9487 - val_categorical_accuracy: 0.9348 - val_loss: 0.9767 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - categorical_accuracy: 0.9457 - loss: 0.9434 - val_categorical_accuracy: 0.9365 - val_loss: 0.9739 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9476 - loss: 0.9352"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - categorical_accuracy: 0.9476 - loss: 0.9352 - val_categorical_accuracy: 0.9400 - val_loss: 0.9617 - learning_rate: 6.2500e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - categorical_accuracy: 0.9497 - loss: 0.9259 - val_categorical_accuracy: 0.9391 - val_loss: 0.9613 - learning_rate: 6.2500e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9506 - loss: 0.9245"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - categorical_accuracy: 0.9506 - loss: 0.9244 - val_categorical_accuracy: 0.9402 - val_loss: 0.9569 - learning_rate: 6.2500e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - categorical_accuracy: 0.9523 - loss: 0.9219 - val_categorical_accuracy: 0.9375 - val_loss: 0.9630 - learning_rate: 6.2500e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - categorical_accuracy: 0.9535 - loss: 0.9171 - val_categorical_accuracy: 0.9388 - val_loss: 0.9585 - learning_rate: 6.2500e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9536 - loss: 0.9121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - categorical_accuracy: 0.9536 - loss: 0.9121 - val_categorical_accuracy: 0.9406 - val_loss: 0.9544 - learning_rate: 3.1250e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - categorical_accuracy: 0.9540 - loss: 0.9107 - val_categorical_accuracy: 0.9402 - val_loss: 0.9522 - learning_rate: 3.1250e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - categorical_accuracy: 0.9571 - loss: 0.9046 - val_categorical_accuracy: 0.9400 - val_loss: 0.9529 - learning_rate: 3.1250e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9569 - loss: 0.9035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - categorical_accuracy: 0.9569 - loss: 0.9035 - val_categorical_accuracy: 0.9411 - val_loss: 0.9541 - learning_rate: 3.1250e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - categorical_accuracy: 0.9566 - loss: 0.9030 - val_categorical_accuracy: 0.9409 - val_loss: 0.9532 - learning_rate: 1.5625e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.9577 - loss: 0.9025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - categorical_accuracy: 0.9577 - loss: 0.9025 - val_categorical_accuracy: 0.9418 - val_loss: 0.9507 - learning_rate: 1.5625e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - categorical_accuracy: 0.9586 - loss: 0.8995 - val_categorical_accuracy: 0.9406 - val_loss: 0.9512 - learning_rate: 1.5625e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - categorical_accuracy: 0.9592 - loss: 0.8975 - val_categorical_accuracy: 0.9411 - val_loss: 0.9524 - learning_rate: 1.5625e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - categorical_accuracy: 0.9600 - loss: 0.8952 - val_categorical_accuracy: 0.9405 - val_loss: 0.9513 - learning_rate: 7.8125e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9604 - loss: 0.8953"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - categorical_accuracy: 0.9603 - loss: 0.8953 - val_categorical_accuracy: 0.9423 - val_loss: 0.9503 - learning_rate: 7.8125e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.9614 - loss: 0.8934"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - categorical_accuracy: 0.9614 - loss: 0.8934 - val_categorical_accuracy: 0.9429 - val_loss: 0.9499 - learning_rate: 7.8125e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - categorical_accuracy: 0.9598 - loss: 0.8942 - val_categorical_accuracy: 0.9426 - val_loss: 0.9489 - learning_rate: 7.8125e-06\n",
      "Epoch 52/100\n",
      "\u001b[1m457/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9605 - loss: 0.8940"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - categorical_accuracy: 0.9605 - loss: 0.8940 - val_categorical_accuracy: 0.9431 - val_loss: 0.9496 - learning_rate: 7.8125e-06\n",
      "Epoch 53/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - categorical_accuracy: 0.9611 - loss: 0.8946 - val_categorical_accuracy: 0.9420 - val_loss: 0.9492 - learning_rate: 7.8125e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - categorical_accuracy: 0.9606 - loss: 0.8931 - val_categorical_accuracy: 0.9415 - val_loss: 0.9489 - learning_rate: 3.9063e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - categorical_accuracy: 0.9595 - loss: 0.8932 - val_categorical_accuracy: 0.9425 - val_loss: 0.9482 - learning_rate: 3.9063e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - categorical_accuracy: 0.9612 - loss: 0.8907 - val_categorical_accuracy: 0.9429 - val_loss: 0.9481 - learning_rate: 3.9063e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - categorical_accuracy: 0.9602 - loss: 0.8923 - val_categorical_accuracy: 0.9426 - val_loss: 0.9479 - learning_rate: 3.9063e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - categorical_accuracy: 0.9614 - loss: 0.8912 - val_categorical_accuracy: 0.9431 - val_loss: 0.9470 - learning_rate: 3.9063e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - categorical_accuracy: 0.9596 - loss: 0.8923 - val_categorical_accuracy: 0.9426 - val_loss: 0.9473 - learning_rate: 3.9063e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - categorical_accuracy: 0.9605 - loss: 0.8905 - val_categorical_accuracy: 0.9420 - val_loss: 0.9474 - learning_rate: 3.9063e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - categorical_accuracy: 0.9625 - loss: 0.8894 - val_categorical_accuracy: 0.9426 - val_loss: 0.9469 - learning_rate: 1.9531e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - categorical_accuracy: 0.9608 - loss: 0.8926 - val_categorical_accuracy: 0.9423 - val_loss: 0.9468 - learning_rate: 1.9531e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "X_train, Y_train,\n",
    "epochs=100,\n",
    "batch_size=128,\n",
    "validation_data=(X_val, Y_val),\n",
    "callbacks=callbacks,\n",
    "class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbd7435d-84a3-4f60-ae2f-1c4aceb39817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating CAPTCHA strings: 100%|█████████████| 722/722 [00:36<00:00, 19.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Character Accuracy: 92.20%\n",
      "String Accuracy: 67.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Trained on combined evaluate on original\n",
    "\n",
    "evaluate_captcha(model, test_dict_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ceea56f2-7dd0-483a-8df7-9578de6ceaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating CAPTCHA strings: 100%|███████████| 1215/1215 [01:00<00:00, 20.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Character Accuracy: 94.00%\n",
      "String Accuracy: 74.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Trained on combined evaluate on combined\n",
    "\n",
    "test_dict_combined = test_dict_ori | test_dict_gan\n",
    "evaluate_captcha(model, test_dict_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf1dc13-dffc-45e8-ba59-0d5bd3be78e0",
   "metadata": {},
   "source": [
    "## Train with GAN-modified original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c871ba8a-e303-4522-8d88-f0771d9383d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_segmented_images_with_GAN_modified(folder_path, gan_modified_folder_path, test_size=0.1):\n",
    "    X_train_list, X_val_list, Y_train_list, Y_val_list = [], [], [], []\n",
    "    test_dict = dict()\n",
    "    captcha_names = os.listdir(folder_path)\n",
    "    train_names, test_names = train_test_split(captcha_names, test_size=test_size, random_state=42)\n",
    "    train_names, val_names = train_test_split(train_names, test_size=test_size, random_state=42)\n",
    "    for captcha_name in captcha_names:\n",
    "        for path in [folder_path, gan_modified_folder_path]:\n",
    "            captcha_dir = os.path.join(path, captcha_name)\n",
    "            if not os.path.isdir(captcha_dir) or len(captcha_name) == 0:\n",
    "                continue\n",
    "            image_files = [fname for fname in os.listdir(captcha_dir)\n",
    "                    if fname.lower().endswith(\".png\") and fname.startswith(\"char_\")]\n",
    "            for filename in image_files:\n",
    "                try:\n",
    "                    char_index = int(filename.split(\"_\")[1].split(\".\")[0])\n",
    "                except Exception:\n",
    "                    continue\n",
    "                if char_index >= len(captcha_name):\n",
    "                    continue\n",
    "                label_char = captcha_name[char_index]\n",
    "                if label_char not in CHARSET:\n",
    "                    continue\n",
    "                label_idx = CHARSET.index(label_char)\n",
    "                img_path = os.path.join(captcha_dir, filename)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                img = resize_and_pad_image(img, 32)\n",
    "                img = img.astype(np.float32) / 255.0\n",
    "                img = np.expand_dims(img, axis=-1)\n",
    "                label = np.zeros(len(CHARSET), dtype=np.float32)\n",
    "                label[label_idx] = 1.0\n",
    "    \n",
    "                if captcha_name in train_names:\n",
    "                    X_train_list.append(img)\n",
    "                    Y_train_list.append(label)\n",
    "\n",
    "                # val set should only have original image\n",
    "                elif captcha_name in val_names and path == folder_path:\n",
    "                    X_val_list.append(img)\n",
    "                    Y_val_list.append(label)\n",
    "\n",
    "                # test set should only have original image\n",
    "                elif captcha_name in test_names and path == folder_path:\n",
    "                    test_dict.setdefault(captcha_name, ([], []))\n",
    "                    test_dict[captcha_name][0].append(img)\n",
    "                    test_dict[captcha_name][1].append(label)\n",
    "    return np.array(X_train_list), np.array(X_val_list), np.array(Y_train_list), np.array(Y_val_list), test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e9f836b-7bf5-4005-ba67-fe86a837b03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 64517 training characters from original and modified, 3837 validation characters from original only; 722 test strings from original only\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val, test_dict = load_segmented_images_with_GAN_modified(\"segmented_new\", \"segmented_ori_modified\")\n",
    "\n",
    "print(f\"Loaded {len(X_train)} training characters from original and modified, \\\n",
    "{len(X_val)} validation characters from original only; \\\n",
    "{len(test_dict)} test strings from original only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e43d2b0-f68e-4e2f-81db-026737e565d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = build_model(num_classes=len(CHARSET))\n",
    "\n",
    "# Enhanced callbacks\n",
    "callbacks = [\n",
    "tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_model_on_combined_data.h5', save_best_only=True, monitor='val_categorical_accuracy'),\n",
    "tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6),\n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_categorical_accuracy', patience=10, \n",
    "    restore_best_weights=True, mode='max', baseline=0.4),\n",
    "tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "\n",
    "# Train with class weights\n",
    "class_counts = np.sum(Y_train, axis=0)\n",
    "class_weights = {i: 1.0 / (count + 1e-5) for i, count in enumerate(class_counts)}\n",
    "class_weights = {k: v / sum(class_weights.values()) * len(CHARSET) for k, v in class_weights.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3878cc73-83ed-4353-a182-ca43bfe8903a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1744740839.647553  532609 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_9_1/dropout_24_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1008/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.3955 - loss: 2.5751"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 21ms/step - categorical_accuracy: 0.3958 - loss: 2.5740 - val_categorical_accuracy: 0.7967 - val_loss: 1.3542 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.7289 - loss: 1.5078 - val_categorical_accuracy: 0.7824 - val_loss: 1.3714 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1007/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.7621 - loss: 1.4307"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - categorical_accuracy: 0.7622 - loss: 1.4306 - val_categorical_accuracy: 0.8327 - val_loss: 1.2343 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1007/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.7926 - loss: 1.3730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - categorical_accuracy: 0.7927 - loss: 1.3730 - val_categorical_accuracy: 0.8348 - val_loss: 1.2611 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.7964 - loss: 1.3933 - val_categorical_accuracy: 0.8285 - val_loss: 1.3275 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.8291 - loss: 1.3166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - categorical_accuracy: 0.8291 - loss: 1.3166 - val_categorical_accuracy: 0.8791 - val_loss: 1.1751 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m1007/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.8446 - loss: 1.2777"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - categorical_accuracy: 0.8446 - loss: 1.2777 - val_categorical_accuracy: 0.8804 - val_loss: 1.1727 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.8542 - loss: 1.2593"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - categorical_accuracy: 0.8542 - loss: 1.2593 - val_categorical_accuracy: 0.8890 - val_loss: 1.1602 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m1008/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.8582 - loss: 1.2555"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - categorical_accuracy: 0.8582 - loss: 1.2555 - val_categorical_accuracy: 0.8991 - val_loss: 1.1579 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - categorical_accuracy: 0.8590 - loss: 1.2582 - val_categorical_accuracy: 0.8947 - val_loss: 1.1624 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.8591 - loss: 1.2707 - val_categorical_accuracy: 0.8952 - val_loss: 1.1735 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m1008/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.8800 - loss: 1.2170"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - categorical_accuracy: 0.8800 - loss: 1.2169 - val_categorical_accuracy: 0.9090 - val_loss: 1.1257 - learning_rate: 2.5000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m1008/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.8911 - loss: 1.1782"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - categorical_accuracy: 0.8911 - loss: 1.1782 - val_categorical_accuracy: 0.9098 - val_loss: 1.1176 - learning_rate: 2.5000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.8958 - loss: 1.1589"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 21ms/step - categorical_accuracy: 0.8958 - loss: 1.1589 - val_categorical_accuracy: 0.9137 - val_loss: 1.1020 - learning_rate: 2.5000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.8987 - loss: 1.1387 - val_categorical_accuracy: 0.9127 - val_loss: 1.0944 - learning_rate: 2.5000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9037 - loss: 1.1272 - val_categorical_accuracy: 0.9127 - val_loss: 1.1007 - learning_rate: 2.5000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.8985 - loss: 1.1294 - val_categorical_accuracy: 0.9088 - val_loss: 1.0913 - learning_rate: 2.5000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m1007/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.9019 - loss: 1.1215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - categorical_accuracy: 0.9019 - loss: 1.1215 - val_categorical_accuracy: 0.9150 - val_loss: 1.0867 - learning_rate: 2.5000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.9050 - loss: 1.1135"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - categorical_accuracy: 0.9050 - loss: 1.1135 - val_categorical_accuracy: 0.9171 - val_loss: 1.0797 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m1008/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.9063 - loss: 1.1059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - categorical_accuracy: 0.9063 - loss: 1.1059 - val_categorical_accuracy: 0.9187 - val_loss: 1.0772 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m1007/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.9059 - loss: 1.1091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - categorical_accuracy: 0.9059 - loss: 1.1091 - val_categorical_accuracy: 0.9189 - val_loss: 1.0697 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m1008/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.9071 - loss: 1.1012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - categorical_accuracy: 0.9071 - loss: 1.1012 - val_categorical_accuracy: 0.9260 - val_loss: 1.0528 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - categorical_accuracy: 0.9104 - loss: 1.0889 - val_categorical_accuracy: 0.9208 - val_loss: 1.0691 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9119 - loss: 1.0829 - val_categorical_accuracy: 0.9166 - val_loss: 1.0749 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9195 - loss: 1.0634 - val_categorical_accuracy: 0.9213 - val_loss: 1.0540 - learning_rate: 1.2500e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - categorical_accuracy: 0.9260 - loss: 1.0407 - val_categorical_accuracy: 0.9255 - val_loss: 1.0502 - learning_rate: 1.2500e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9254 - loss: 1.0400 - val_categorical_accuracy: 0.9252 - val_loss: 1.0445 - learning_rate: 1.2500e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m1007/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.9300 - loss: 1.0286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - categorical_accuracy: 0.9300 - loss: 1.0286 - val_categorical_accuracy: 0.9302 - val_loss: 1.0343 - learning_rate: 1.2500e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9275 - loss: 1.0276 - val_categorical_accuracy: 0.9260 - val_loss: 1.0299 - learning_rate: 1.2500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - categorical_accuracy: 0.9296 - loss: 1.0204 - val_categorical_accuracy: 0.9275 - val_loss: 1.0387 - learning_rate: 1.2500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m1007/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.9296 - loss: 1.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - categorical_accuracy: 0.9296 - loss: 1.0203 - val_categorical_accuracy: 0.9309 - val_loss: 1.0265 - learning_rate: 1.2500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9311 - loss: 1.0127 - val_categorical_accuracy: 0.9268 - val_loss: 1.0299 - learning_rate: 1.2500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - categorical_accuracy: 0.9314 - loss: 1.0100 - val_categorical_accuracy: 0.9273 - val_loss: 1.0279 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.9378 - loss: 0.9926"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - categorical_accuracy: 0.9378 - loss: 0.9926 - val_categorical_accuracy: 0.9330 - val_loss: 1.0171 - learning_rate: 6.2500e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - categorical_accuracy: 0.9412 - loss: 0.9813 - val_categorical_accuracy: 0.9317 - val_loss: 1.0173 - learning_rate: 6.2500e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m1008/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.9423 - loss: 0.9789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - categorical_accuracy: 0.9423 - loss: 0.9789 - val_categorical_accuracy: 0.9338 - val_loss: 1.0149 - learning_rate: 6.2500e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.9440 - loss: 0.9759"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - categorical_accuracy: 0.9439 - loss: 0.9759 - val_categorical_accuracy: 0.9346 - val_loss: 1.0066 - learning_rate: 6.2500e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - categorical_accuracy: 0.9427 - loss: 0.9725 - val_categorical_accuracy: 0.9309 - val_loss: 1.0117 - learning_rate: 6.2500e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9432 - loss: 0.9697 - val_categorical_accuracy: 0.9315 - val_loss: 1.0156 - learning_rate: 6.2500e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9466 - loss: 0.9607 - val_categorical_accuracy: 0.9315 - val_loss: 1.0080 - learning_rate: 3.1250e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9483 - loss: 0.9551 - val_categorical_accuracy: 0.9309 - val_loss: 1.0099 - learning_rate: 3.1250e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9485 - loss: 0.9525 - val_categorical_accuracy: 0.9343 - val_loss: 1.0055 - learning_rate: 1.5625e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m1007/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.9495 - loss: 0.9490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - categorical_accuracy: 0.9495 - loss: 0.9490 - val_categorical_accuracy: 0.9351 - val_loss: 1.0042 - learning_rate: 1.5625e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - categorical_accuracy: 0.9510 - loss: 0.9480 - val_categorical_accuracy: 0.9333 - val_loss: 1.0046 - learning_rate: 1.5625e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.9508 - loss: 0.9467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - categorical_accuracy: 0.9508 - loss: 0.9467 - val_categorical_accuracy: 0.9354 - val_loss: 1.0015 - learning_rate: 1.5625e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - categorical_accuracy: 0.9509 - loss: 0.9474 - val_categorical_accuracy: 0.9346 - val_loss: 0.9996 - learning_rate: 1.5625e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9519 - loss: 0.9436 - val_categorical_accuracy: 0.9346 - val_loss: 1.0005 - learning_rate: 1.5625e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9517 - loss: 0.9434 - val_categorical_accuracy: 0.9343 - val_loss: 0.9980 - learning_rate: 1.5625e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9524 - loss: 0.9405 - val_categorical_accuracy: 0.9317 - val_loss: 0.9985 - learning_rate: 1.5625e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9542 - loss: 0.9361 - val_categorical_accuracy: 0.9351 - val_loss: 1.0001 - learning_rate: 1.5625e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9530 - loss: 0.9392 - val_categorical_accuracy: 0.9351 - val_loss: 0.9969 - learning_rate: 7.8125e-06\n",
      "Epoch 52/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - categorical_accuracy: 0.9534 - loss: 0.9354 - val_categorical_accuracy: 0.9333 - val_loss: 0.9992 - learning_rate: 7.8125e-06\n",
      "Epoch 53/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9541 - loss: 0.9373 - val_categorical_accuracy: 0.9341 - val_loss: 0.9987 - learning_rate: 7.8125e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9546 - loss: 0.9349 - val_categorical_accuracy: 0.9333 - val_loss: 0.9980 - learning_rate: 3.9063e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - categorical_accuracy: 0.9560 - loss: 0.9336 - val_categorical_accuracy: 0.9346 - val_loss: 0.9973 - learning_rate: 3.9063e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "X_train, Y_train,\n",
    "epochs=100,\n",
    "batch_size=64,\n",
    "validation_data=(X_val, Y_val),\n",
    "callbacks=callbacks,\n",
    "class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6deac0c8-18dc-4fcc-a002-cf44ffcb0544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating CAPTCHA strings: 100%|█████████████| 722/722 [00:34<00:00, 20.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Character Accuracy: 92.50%\n",
      "String Accuracy: 68.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Evaluate on hold-out original\n",
    "evaluate_captcha(model, test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaf5e84-6aea-4ce6-ac4d-2d8aca6b5e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
