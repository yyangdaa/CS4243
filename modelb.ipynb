{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, callbacks, optimizers, mixed_precision\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecayRestarts\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "img_w, img_h     = 300, 80       # CAPTCHA size\n",
    "batch_size       = 16\n",
    "max_label_len    = 10\n",
    "chars            = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "num_classes      = len(chars) + 1  # +1 for CTC blank\n",
    "blank_label      = num_classes - 1\n",
    "\n",
    "data_dir         = 'preprocessing/preprocessed_images'\n",
    "all_paths        = glob.glob(os.path.join(data_dir, '*.png'))\n",
    "np.random.shuffle(all_paths)\n",
    "n = len(all_paths)\n",
    "train_paths = all_paths[:int(0.7 * n)]\n",
    "val_paths   = all_paths[int(0.7 * n):]\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "char_to_num = {c: i for i, c in enumerate(chars)}\n",
    "num_to_char = {i: c for c, i in char_to_num.items()}\n",
    "\n",
    "def make_label_arrays(paths):\n",
    "    seqs, lens = [], []\n",
    "    for p in paths:\n",
    "        name  = os.path.basename(p)\n",
    "        label = name.split('-', 1)[0]                  \n",
    "        arr   = [char_to_num[c] for c in label if c in char_to_num]\n",
    "        arr   = arr[:max_label_len]\n",
    "        lens.append(len(arr))\n",
    "        arr  += [blank_label] * (max_label_len - len(arr))  # pad\n",
    "        seqs.append(arr)\n",
    "    return np.array(seqs, dtype=np.int32), np.array(lens, dtype=np.int32)\n",
    "\n",
    "train_labels, train_lens = make_label_arrays(train_paths)\n",
    "val_labels,   val_lens   = make_label_arrays(val_paths)\n",
    "\n",
    "def load_and_preprocess(path, lbl_seq, lbl_len):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    img = tf.image.resize(img, [img_h, img_w])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "\n",
    "    img = tf.image.random_brightness(img, 0.2)\n",
    "    img = tf.image.random_contrast(img, 0.5, 1.5)\n",
    "\n",
    "    return {'input_image': img, 'labels': lbl_seq, 'label_length': lbl_len}, 0.0\n",
    "\n",
    "def make_dataset(paths, labels, lens, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels, lens))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(paths), reshuffle_each_iteration=True)\n",
    "    ds = ds.map(load_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.cache()\n",
    "    ds = ds.batch(batch_size * 2, drop_remainder=True)  \n",
    "    ds = ds.prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_dataset(train_paths, train_labels, train_lens, shuffle=True)\n",
    "val_ds   = make_dataset(val_paths,   val_labels,   val_lens,   shuffle=False)\n",
    "\n",
    "def build_crnn():\n",
    "    inp     = layers.Input((img_h, img_w, 1), name='input_image')\n",
    "    labels  = layers.Input((max_label_len,), dtype='int32', name='labels')\n",
    "    lbl_len = layers.Input((), dtype='int32', name='label_length')\n",
    "\n",
    "    x = inp\n",
    "    pools = [(2,2),(2,2),(2,1),(2,1)]\n",
    "    for filters, pool in zip([64,128,256,512], pools):\n",
    "        x = layers.Conv2D(filters, 3, padding='same', use_bias=False)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.LeakyReLU()(x)\n",
    "        x = layers.MaxPooling2D(pool)(x)\n",
    "\n",
    "    time_steps  = img_w // 4\n",
    "    height_pool = img_h // 16\n",
    "    flat_dim    = height_pool * 512\n",
    "\n",
    "    x = layers.Permute((2,1,3))(x)\n",
    "    x = layers.Reshape((time_steps, flat_dim))(x)\n",
    "\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=0.3))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=0.3))(x)\n",
    "\n",
    "    y_pred = layers.Dense(num_classes, activation='softmax', name='y_pred')(x)\n",
    "\n",
    "    def ctc_loss_fn(args):\n",
    "        y_p, lbls, ll = args\n",
    "        b   = tf.shape(y_p)[0]\n",
    "        t   = tf.shape(y_p)[1]\n",
    "        il  = tf.fill([b,1], t)\n",
    "        ll2 = tf.reshape(ll, [b,1])\n",
    "        return tf.keras.backend.ctc_batch_cost(lbls, y_p, il, ll2)\n",
    "\n",
    "    def ctc_out_shape(shapes):\n",
    "        return (shapes[0][0], 1)\n",
    "\n",
    "    loss_out = layers.Lambda(\n",
    "        ctc_loss_fn,\n",
    "        output_shape=ctc_out_shape,\n",
    "        name='ctc'\n",
    "    )([y_pred, labels, lbl_len])\n",
    "\n",
    "    model   = tf.keras.Model([inp, labels, lbl_len], loss_out)\n",
    "    pred_md = tf.keras.Model(inp, y_pred)\n",
    "    return model, pred_md\n",
    "\n",
    "model, pred_model = build_crnn()\n",
    "model.summary()\n",
    "\n",
    "class CTCMonitor(Callback):\n",
    "    def __init__(self, dataset, name):\n",
    "        self.ds, self.name = dataset, name\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        tot_s=cor_s=tot_c=cor_c=0\n",
    "        for batch in self.ds:\n",
    "            imgs = batch[0]['input_image']\n",
    "            lbls = batch[0]['labels'].numpy()\n",
    "            preds = pred_model.predict(imgs, verbose=0)\n",
    "            L = np.ones(preds.shape[0]) * preds.shape[1]\n",
    "            decs,_ = tf.keras.backend.ctc_decode(\n",
    "                preds, input_length=L,\n",
    "                greedy=False, beam_width=5, top_paths=1\n",
    "            )\n",
    "            for p, t in zip(decs[0].numpy(), lbls):\n",
    "                s   = ''.join(num_to_char[i] for i in p   if i!=blank_label)\n",
    "                t_s = ''.join(num_to_char[i] for i in t   if i!=blank_label)\n",
    "                tot_s += 1\n",
    "                cor_s += (s==t_s)\n",
    "                tot_c += len(t_s)\n",
    "                cor_c += sum(s[i]==t_s[i] for i in range(min(len(s),len(t_s))))\n",
    "        sa, ca = cor_s/tot_s, cor_c/tot_c\n",
    "        print(f\"\\n[{self.name}] string_acc={sa:.2%}, char_acc={ca:.2%}\")\n",
    "        if self.name=='Val': logs['val_string_acc'] = sa\n",
    "\n",
    "steps   = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "lr_sched = CosineDecayRestarts(\n",
    "    initial_learning_rate=1e-3,\n",
    "    first_decay_steps=steps*5,\n",
    "    t_mul=2.0, m_mul=1.0, alpha=1e-6\n",
    ")\n",
    "opt = AdamW(\n",
    "    learning_rate=lr_sched,\n",
    "    weight_decay=1e-5,\n",
    "    clipnorm=5.0\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss={'ctc': lambda y_true, y_pred: y_pred}\n",
    ")\n",
    "\n",
    "cbs = [\n",
    "    CTCMonitor(train_ds, 'Train'),\n",
    "    CTCMonitor(val_ds,   'Val'),\n",
    "    ModelCheckpoint('best_crnn.h5', monitor='val_string_acc',\n",
    "                    save_best_only=True, mode='max', verbose=1),\n",
    "    EarlyStopping(monitor='val_string_acc', patience=10,\n",
    "                  restore_best_weights=True, mode='max', verbose=1)\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a11a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=100,\n",
    "    callbacks=cbs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01fc13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, eval_paths, batch_size, name=\"Test\"):\n",
    "    # Make label arrays from paths\n",
    "    eval_labels, eval_lens = make_label_arrays(eval_paths)\n",
    "\n",
    "    eval_ds = make_dataset(eval_paths, eval_labels, eval_lens, shuffle=False)\n",
    "\n",
    "    pred_model = keras.Model(\n",
    "        inputs=model.get_layer('input_image').input,\n",
    "        outputs=model.get_layer('y_pred').output\n",
    "    )\n",
    "\n",
    "    total_strings = 0\n",
    "    correct_strings = 0\n",
    "    total_chars = 0\n",
    "    correct_chars = 0\n",
    "\n",
    "    for batch in eval_ds:\n",
    "        imgs = batch[0]['input_image']\n",
    "        lbls = batch[0]['labels'].numpy()\n",
    "\n",
    "        preds = pred_model.predict(imgs, verbose=0)\n",
    "        input_lengths = np.ones(preds.shape[0]) * preds.shape[1]\n",
    "\n",
    "        decoded, _ = tf.keras.backend.ctc_decode(\n",
    "            preds, input_length=input_lengths,\n",
    "            greedy=False, beam_width=5, top_paths=1\n",
    "        )\n",
    "        decoded = decoded[0].numpy()\n",
    "\n",
    "        for i, pred_seq in enumerate(decoded):\n",
    "            pred_text = ''.join(num_to_char.get(ch, '') for ch in pred_seq if ch != blank_label)\n",
    "            true_text = ''.join(num_to_char.get(ch, '') for ch in lbls[i] if ch != blank_label)\n",
    "\n",
    "            if pred_text == true_text:\n",
    "                correct_strings += 1\n",
    "            total_strings += 1\n",
    "\n",
    "            match_len = min(len(pred_text), len(true_text))\n",
    "            correct_chars += sum(1 for a, b in zip(pred_text, true_text) if a == b)\n",
    "            total_chars += len(true_text)\n",
    "\n",
    "    string_acc = (correct_strings / total_strings) if total_strings else 0\n",
    "    char_acc = (correct_chars / total_chars) if total_chars else 0\n",
    "    print(f\"\\n[{name}] Final Evaluation:\")\n",
    "    print(f\"String Accuracy:    {string_acc:.2%}\")\n",
    "    print(f\"Character Accuracy: {char_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a36466",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, val_paths, batch_size, name=\"Validation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
